{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Building a Part of Speech Tagger with Word2Vec and Scikit-Learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're using the training and test sets from this link: [Chunking](http://www.cnts.ua.ac.be/conll2000/chunking/).\n",
      "\n",
      "[Training file](http://www.cnts.ua.ac.be/conll2000/chunking/train.txt.gz).\n",
      "\n",
      "[Test file](http://www.cnts.ua.ac.be/conll2000/chunking/test.txt.gz)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's pull in word2vec first.\n",
      "from gensim.models import Word2Vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to try a few different classifiers, so we import them here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# then let's get some classifiers from sklearn\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn import neighbors\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We build a word model using pre-trained 300-dimensional word vectors from Google. This is a 2GB file...\n",
      "\n",
      "[Pre-trained word and phrase vectors](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing).\n",
      "\n",
      "You can read more about the data [here](https://code.google.com/p/word2vec/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build the gensim model\n",
      "word_model = Word2Vec.load_word2vec_format('/Users/richard/data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The similarity function implements cosine similarity, which we use here just to see that the data was loaded correctly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check that the model is loaded correctly - similary(man,woman) should be about .76\n",
      "word_model.similarity('man', 'woman')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0.76640122309953529"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build dictionary from words to POS, build set of POS\n",
      "training_file = open('/Users/richard/data/pos/train', 'r')\n",
      "parts_of_speech = {}\n",
      "pos_tags = set()\n",
      "for line in training_file:\n",
      "    #print line\n",
      "    # note we're assuming that the training data is correct.\n",
      "    parts = line.split()\n",
      "    if len(parts) != 3: continue\n",
      "    parts_of_speech[parts[0]] = parts[1]\n",
      "    pos_tags.add(parts[1])\n",
      "    \n",
      "pos_tag_list = list(pos_tags)\n",
      "print pos_tag_list\n",
      "print \"Number of possible tags: \", len(pos_tag_list)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['PRP$', 'VBG', 'VBD', '``', ',', \"''\", 'VBP', 'WDT', 'JJ', 'WP', 'VBZ', 'DT', '#', 'RP', '$', 'NN', ')', '(', 'FW', 'POS', '.', 'TO', 'PRP', 'RB', ':', 'NNS', 'NNP', 'VB', 'WRB', 'CC', 'PDT', 'RBS', 'RBR', 'VBN', 'EX', 'IN', 'WP$', 'CD', 'MD', 'NNPS', 'JJS', 'JJR', 'SYM', 'UH']\n",
        "Number of possible tags:  44\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we put the data into the format the sklearn expects: a matrix of the feature vectors (one row is one example), and a vector of the labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build the training set feature matrix and label vector\n",
      "training_features = []\n",
      "training_labels = []\n",
      "for word, pos in parts_of_speech.iteritems():\n",
      "    if not word in word_model: continue\n",
      "\n",
      "    training_features.append(word_model[word])\n",
      "    training_labels.append(pos_tag_list.index(pos))\n",
      "    \n",
      "feature_matrix = np.vstack(training_features)\n",
      "label_vector = np.asarray(training_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_matrix.shape\n",
      "print label_vector.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(15546, 300)\n",
        "(15546,)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We train four classifiers. Scikit-learn makes this pretty trivial:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_classifier = LogisticRegression()\n",
      "print \"Training logistic regression classifier.\"\n",
      "lr_classifier.fit(feature_matrix, label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training logistic regression classifier.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knn_classifier = neighbors.KNeighborsClassifier()\n",
      "print \"Training kNN classifier, k = 5.\"\n",
      "knn_classifier.fit(feature_matrix, label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_classifier = SVC()\n",
      "print \"Training SVM classifier.\"\n",
      "svc_classifier.fit(feature_matrix, label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_classifier = RandomForestClassifier()\n",
      "print \"Training Random Forest classifier.\"\n",
      "rf_classifier.fit(feature_matrix, label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_file = open('/Users/richard/data/pos/test', 'r')\n",
      "test_parts_of_speech = {}\n",
      "for line in test_file:\n",
      "    parts = line.split()\n",
      "    if len(parts) != 3: continue\n",
      "    test_parts_of_speech[parts[0]] = parts[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We skip words that aren't in the word model. You could argue that this inflates our scores, but we're just having fun. If this were serious work, we would have to handle unfamiliar words in a sensible way. We're using the same data for each of the classifiers, so there's that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build the training set feature matrix and label vector\n",
      "test_features = []\n",
      "test_labels = []\n",
      "for word, pos in test_parts_of_speech.iteritems():\n",
      "    if not word in word_model: continue\n",
      "\n",
      "    test_features.append(word_model[word])\n",
      "    test_labels.append(pos_tag_list.index(pos))\n",
      "    \n",
      "test_feature_matrix = np.vstack(test_features)\n",
      "test_label_vector = np.asarray(test_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_feature_matrix.shape\n",
      "print test_label_vector.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6945, 300)\n",
        "(6945,)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The score function returns the mean accuracy on the given feature matrix and label vector. To show how that works, we compute the score for logistic regression by hand, and then confirm that the result we compute is the same as the number returned by the score function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check that our scores are reasonable.\n",
      "correct = 0\n",
      "for i in range(6945):\n",
      "    if lr_classifier.predict(test_feature_matrix[i, :]) == test_label_vector[i]:\n",
      "        correct += 1\n",
      "\n",
      "print correct / (1.0 * 6945)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.876889848812\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This should give 0.876889848812\n",
      "print lr_classifier.score(test_feature_matrix, test_label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.876889848812\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This should give 0.708999280058\n",
      "print knn_classifier.score(test_feature_matrix, test_label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.708999280058\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This should give 0.809935205184\n",
      "print svc_classifier.score(test_feature_matrix, test_label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.809935205184\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This should give 0.803455723542\n",
      "print rf_classifier.score(test_feature_matrix, test_label_vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.803455723542\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Some Examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are some predictions of the logistic regression classifier. If you want to know what the tags mean, check out [The Penn Treebank P.O.S. Tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['cat'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "'NN'"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['books'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "'NNS'"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['ghosts'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "'NNS'"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['ghost'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "'NN'"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['running'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "'VBG'"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['elective'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "'JJ'"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['Richard'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "'NNP'"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['Titanic'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "'NNP'"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag_list[lr_classifier.predict(word_model['titanic'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "'JJ'"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}