{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Stochastic Gradient Descent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.linear_model import SGDClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, neighbors\n",
      "(easy_x, easy_y) = datasets.make_classification(n_samples=400, n_features = 2, n_informative = 2,\n",
      "                             n_redundant = 0, n_repeated = 0, n_clusters_per_class=1, class_sep=4)\n",
      "scatter(easy_x[:,0], easy_x[:,1], c = easy_y, cmap = 'cool')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sgd_clf = SGDClassifier(n_iter=10000, alpha=0.001, loss=\"log\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sgd_clf.fit(easy_x, easy_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sgd_clf.predict([4,-4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = 0.05 # mesh size\n",
      "x_min, x_max = easy_x[:, 0].min() - 1, easy_x[:,0].max() + 1\n",
      "y_min, y_max = easy_x[:, 1].min() - 1, easy_x[:,1].max() + 1\n",
      "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "Z = sgd_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "Z = Z.reshape(xx.shape)\n",
      "figure()\n",
      "pcolormesh(xx,yy, Z, cmap='cool')\n",
      "\n",
      "# this line plots the training data\n",
      "scatter(easy_x[:,0], easy_x[:,1], c=easy_y, cmap='cool')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "lr_classifier = LogisticRegression()\n",
      "lr_classifier.fit(easy_x, easy_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotting...\n",
      "Z_lr = lr_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "Z_lr = Z_lr.reshape(xx.shape)\n",
      "figure()\n",
      "pcolormesh(xx,yy, Z_lr, cmap='cool')\n",
      "scatter(easy_x[:,0], easy_x[:,1], c=easy_y, cmap='cool')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What's SGD Doing?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parametric Models and Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We are given a set of _examples_ of the form $(x_i, y_i)$, where $x_i \\in \\mathbb{R}^n$ and $y_i \\in \\{-1,1\\}$.\n",
      "\n",
      "* We want to learn a function $f(x; w)$ whose output will tell us what class $x$ is in, for any given $x$.\n",
      "\n",
      "* The $f$ is defined in terms of a set of parameters, and in the case above is linear: $f(x) = w^T x + b$.\n",
      "\n",
      "* We suppose that, for a given training pair $(x_i, y_i)$, we can measure the quality of the current output of $f$ with some _loss function_, $L(y_i, f(x_i))$.\n",
      "\n",
      "* We can then define an _error function_ like so:\n",
      "\n",
      "    $E(w,b) = \\sum_{i=1}^N L(y_i, f(x_i))$\n",
      "    \n",
      "* Then the goal is to find the $w$ and $b$ that minimize the total error. This should give us a function that works well on new data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* In the case of logistic regression, we choose the loss function to be `log`."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Gradient Descent Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* How do we optimize simple univariate functions?\n",
      "\n",
      "* How do we optimize in the case of linear regression?\n",
      "\n",
      "    * $\\hat{w}_{ols} = (X^T X)^{-1} X^T y$, where $X^TX = \\sum_{i=1}^N x_i x_i^T$ and $X^T y = \\sum_{i=1}^N x_i y_i$. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Taken from scikit-learn's docs.\n",
      "\n",
      "from sklearn import datasets, linear_model\n",
      "\n",
      "# Load the diabetes dataset\n",
      "diabetes = datasets.load_diabetes()\n",
      "\n",
      "# Use only one feature\n",
      "diabetes_X = diabetes.data[:, np.newaxis]\n",
      "diabetes_X_temp = diabetes_X[:, :, 2]\n",
      "\n",
      "# Split the data into training/testing sets\n",
      "diabetes_X_train = diabetes_X_temp[:-20]\n",
      "diabetes_X_test = diabetes_X_temp[-20:]\n",
      "\n",
      "# Split the targets into training/testing sets\n",
      "diabetes_y_train = diabetes.target[:-20]\n",
      "diabetes_y_test = diabetes.target[-20:]\n",
      "\n",
      "# Create linear regression object\n",
      "regr = linear_model.LinearRegression()\n",
      "\n",
      "# Train the model using the training sets\n",
      "regr.fit(diabetes_X_train, diabetes_y_train)\n",
      "\n",
      "# The coefficients\n",
      "print('Coefficients: \\n', regr.coef_)\n",
      "# The mean square error\n",
      "print(\"Residual sum of squares: %.2f\"\n",
      "      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n",
      "# Explained variance score: 1 is perfect prediction\n",
      "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
      "\n",
      "# Plot outputs\n",
      "scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
      "\n",
      "\n",
      "#plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue', linewidth=3)\n",
      "\n",
      "\n",
      "\n",
      "xticks(())\n",
      "yticks(())\n",
      "\n",
      "show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* What happens when the function is really complicated?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Example on the board"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Regularization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Let's look at wolfram alpha..."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "{{1,1},{3,15},{4,4},{9,9},{16,16},{6,10},{12,5}}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Here, we are _overfitting_ the data (on purpose, because we told the system to do interpolation). This leads to a model with huge swings in coefficients..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can solve this problem by changing the error function:\n",
      "\n",
      "    * $E(w,b) = \\sum_{i=1}^N L(y_i, f(x_i)) + \\alpha R(w)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does this change?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}